{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9ed7553f-425c-4504-b420-86eb996f623a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://rmsryu-vm.internal.cloudapp.net:4042\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.2.3</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>pyspark-shell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<SparkContext master=local[*] appName=pyspark-shell>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c7d0dd1",
   "metadata": {},
   "source": [
    "# Loading (remote) E-OBS observations and summer days (SU) calculation\n",
    "\n",
    "Git repo: https://github.com/rmsryu/spark-climate-data.git\n",
    "Data set: https://www.ecad.eu/download/ensembles/download.php\n",
    "\n",
    "E-OBS data is loaded from the remote OpenDAP repository at KNMI. Please, note that when new versions become available the link is no longer valid since the URL is updated with the version number. Therefore, if the code below doesn't work please check the current E-OBS version and update the URL (https://www.ecad.eu/download/ensembles/download.php). \n",
    "\n",
    "# Study of daily precipitation from Station Aalsmeer Netherlands\n",
    "Data source: https://climexp.knmi.nl/data/rrrr458.dat\n",
    "Data provide by: Royal Netherlands Meteorological Institute (KNMI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "77387014",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pyspark import SparkFiles\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import *\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4c9dcb4e-d35d-48cc-b82a-59011025d8bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "80e6ce84-7181-4764-a5f0-b1a12076e030",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "hadoopUrl = 'hdfs://hadoop-vm.internal.cloudapp.net:9000'\n",
    "data_files = f'{hadoopUrl}/precipitation/data/*/*.parquet'\n",
    "# Obtain dataset\n",
    "data = spark.read.parquet(data_files)\n",
    "data = data.withColumn(\"precipitation\", col(\"precipitation\").cast(\"float\"))\n",
    "data = data.withColumn(\"date\", col(\"date\").cast(\"date\"))\n",
    "data.createOrReplaceTempView(\"precipitations\")\n",
    "data.cache()\n",
    "\n",
    "# Read Station Info\n",
    "schema_stations = StructType([\n",
    "        StructField(\"station\", StringType(), True),\n",
    "        StructField(\"name\", StringType(), True),\n",
    "        StructField(\"latitude\", FloatType(), True),\n",
    "        StructField(\"longitude\", FloatType(), True),\n",
    "        StructField(\"website\", StringType(), True),\n",
    "        StructField(\"rawdata\", StringType(), True),\n",
    "        StructField(\"filename\", StringType(), True),\n",
    "        StructField(\"from\", StringType(), True),\n",
    "        StructField(\"to\", StringType(), True)\n",
    "    ])\n",
    "station_files = 'hdfs://hadoop-vm.internal.cloudapp.net:9000/precipitation/data/stations/*.csv'\n",
    "stations = spark.read.csv(station_files,schema=schema_stations)\n",
    "stations.withColumn(\"from\", col(\"from\").cast(\"date\"))\n",
    "stations.withColumn(\"to\", col(\"to\").cast(\"date\"))\n",
    "stations.createOrReplaceTempView(\"stations\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eaf9211c-2afb-4492-9756-1b14831f27c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 4:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+-----------------+\n",
      "|summary|           station|    precipitation|\n",
      "+-------+------------------+-----------------+\n",
      "|  count|          13120148|         13120148|\n",
      "|   mean|483.02698064076714| 2.13989743152896|\n",
      "| stddev|287.72368836944077|4.339730993138887|\n",
      "|    min|               001|              0.0|\n",
      "|    25%|             228.0|              0.0|\n",
      "|    50%|             466.0|              0.1|\n",
      "|    75%|             737.0|              2.4|\n",
      "|    max|               983|            208.0|\n",
      "+-------+------------------+-----------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "data.summary().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d58b7956-6982-4bd0-8a1f-1a7a647cae19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+--------+---------+--------------------+--------------------+------------+----------+----------+\n",
      "|station|                name|latitude|longitude|             website|             rawdata|    filename|      from|        to|\n",
      "+-------+--------------------+--------+---------+--------------------+--------------------+------------+----------+----------+\n",
      "|    458|            Aalsmeer|   52.25|     4.77|https://climexp.k...|https://climexp.k...|rrrr458.data|1927-01-02|2023-03-10|\n",
      "|    040|   Aalsum bij Dokkum|  -999.9|   -999.9|https://climexp.k...|https://climexp.k...|rrrr040.data|1892-12-29|1925-09-30|\n",
      "|    680|              Aalten|    51.9|     6.55|https://climexp.k...|https://climexp.k...|rrrr680.data|1904-08-02|2023-03-10|\n",
      "|    711|          Aardenburg|  -999.9|   -999.9|https://climexp.k...|https://climexp.k...|rrrr711.data|1873-12-01|1887-06-30|\n",
      "|    572|             Abcoude|   52.25|     4.97|https://climexp.k...|https://climexp.k...|rrrr572.data|1930-09-02|2023-03-10|\n",
      "|    045|              Akkrum|  -999.9|   -999.9|https://climexp.k...|https://climexp.k...|rrrr045.data|1882-10-01|1937-04-30|\n",
      "|    089|              Akkrum|   53.05|     5.82|https://climexp.k...|https://climexp.k...|rrrr089.data|1995-10-01|2023-03-10|\n",
      "|    200|             Alkmaar|  -999.9|   -999.9|https://climexp.k...|https://climexp.k...|rrrr200.data|1880-03-02|1941-09-01|\n",
      "|    664|              Almelo|   52.33|     6.67|https://climexp.k...|https://climexp.k...|rrrr664.data|1880-08-02|2023-03-10|\n",
      "|    678|               Almen|   52.15|     6.32|https://climexp.k...|https://climexp.k...|rrrr678.data|1950-03-02|2023-03-10|\n",
      "|    363|Alteveer (Hoogeveen)|  -999.9|   -999.9|https://climexp.k...|https://climexp.k...|rrrr363.data|1916-11-01|1922-09-30|\n",
      "|    169|                Amen|  -999.9|   -999.9|https://climexp.k...|https://climexp.k...|rrrr169.data|1968-01-01|1975-01-01|\n",
      "|    560|           Amerongen|   51.98|     5.45|https://climexp.k...|https://climexp.k...|rrrr560.data|1910-04-09|2023-03-10|\n",
      "|    515|          Amersfoort|  -999.9|   -999.9|https://climexp.k...|https://climexp.k...|rrrr515.data|1880-05-01|1948-04-01|\n",
      "|    529|Amersfoort (Tutei...|  -999.9|   -999.9|https://climexp.k...|https://climexp.k...|rrrr529.data|1928-01-01|1934-12-31|\n",
      "|    910|          Ammerzoden|   51.73|      5.2|https://climexp.k...|https://climexp.k...|rrrr910.data|1932-10-14|2023-03-10|\n",
      "|    441|           Amsterdam|   52.37|     4.92|https://climexp.k...|https://climexp.k...|rrrr441.data|1916-01-01|2015-01-01|\n",
      "|    433|Amsterdam Anwi (Fil)|  -999.9|   -999.9|https://climexp.k...|https://climexp.k...|rrrr433.data|1880-01-01|1962-01-01|\n",
      "|    835|               Andel|   51.78|     5.05|https://climexp.k...|https://climexp.k...|rrrr835.data|1912-02-24|2023-03-10|\n",
      "|    205|              Andijk|  -999.9|   -999.9|https://climexp.k...|https://climexp.k...|rrrr205.data|1904-01-01|1935-10-31|\n",
      "+-------+--------------------+--------+---------+--------------------+--------------------+------------+----------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "stations.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1d56bd7-b011-43dd-99ad-552edcd8e7f5",
   "metadata": {},
   "source": [
    "# Stations stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e2d78c67-904e-4d66-8b77-ecaaeb154313",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 8:>                                                          (0 + 2) / 2]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------+---------+-----+------------------+------------------+---+-----+-------------------+------------------+-----+\n",
      "|station|min_year|num_years|count|              mean|            stddev|min|25pct|              50pct|             75pct|  max|\n",
      "+-------+--------+---------+-----+------------------+------------------+---+-----+-------------------+------------------+-----+\n",
      "|    001|    1940|       83|29556| 2.174519556030149| 4.370148656161713|0.0|  0.0|0.10000000149011612|               2.5| 76.6|\n",
      "|    003|    1902|       51|18482|2.0838329184571815| 4.277456332945257|0.0|  0.0|0.10000000149011612| 2.299999952316284| 78.4|\n",
      "|    004|    1904|        1|  419| 1.617899758558996|3.4800441747162214|0.0|  0.0|0.10000000149011612| 1.399999976158142| 26.9|\n",
      "|    006|    1905|       38|13970|1.7968360776213679| 3.740703703355201|0.0|  0.0|0.10000000149011612| 1.899999976158142| 82.1|\n",
      "|    007|    1906|       44|15101|1.9131845566100272|3.8756137261021313|0.0|  0.0|                0.0| 2.200000047683716| 64.7|\n",
      "|    008|    1937|        3| 1096|1.5393248179614762|3.4753844346339866|0.0|  0.0|                0.0| 1.600000023841858| 38.0|\n",
      "|    009|    1851|      121|44406|1.8896342841528726|3.8899340549232315|0.0|  0.0|0.10000000149011612|2.0999999046325684| 83.3|\n",
      "|    010|    1872|      151|52324|2.0548104115429116| 4.179136243163778|0.0|  0.0|                0.0|2.4000000953674316|109.4|\n",
      "|    011|    1876|      147|53758| 2.082222180832206| 4.201727303440663|0.0|  0.0|0.10000000149011612|2.4000000953674316| 91.0|\n",
      "|    012|    1879|      144|42144| 2.113351841111213| 4.162499025008069|0.0|  0.0|                0.0|               2.5| 78.9|\n",
      "|    013|    1885|      100|15262| 2.010267331447858|3.9819975326866857|0.0|  0.0|0.20000000298023224| 2.299999952316284| 57.9|\n",
      "|    014|    1885|       67| 7476|1.7431514188726998| 3.773894477530973|0.0|  0.0|                0.0|1.7999999523162842| 56.0|\n",
      "|    015|    1885|      138|49809| 2.089361360136142| 4.329440914202082|0.0|  0.0|                0.0|2.4000000953674316| 85.5|\n",
      "|    016|    1891|      132|48159|2.0030503136297924| 4.152152517357461|0.0|  0.0|0.10000000149011612| 2.200000047683716|112.3|\n",
      "|    017|    1894|      129|29843|2.1887645339229724| 4.318287714354467|0.0|  0.0|0.20000000298023224|               2.5| 57.5|\n",
      "|    018|    1916|      107|36771|2.2269125135079992| 4.474478831477688|0.0|  0.0|0.10000000149011612| 2.700000047683716| 87.2|\n",
      "|    019|    1929|       94|34221|2.1881330180013485|4.3172841497787715|0.0|  0.0|0.20000000298023224|               2.5| 67.5|\n",
      "|    021|    1940|       83|29594|2.1730249374286683|4.3682149079767045|0.0|  0.0|0.10000000149011612|               2.5| 76.6|\n",
      "|    022|    1950|       73|26537|2.2094773349523833| 4.390459839096478|0.0|  0.0|0.20000000298023224|               2.5| 68.3|\n",
      "|    023|    1876|        9| 1824|1.8230263121066648| 3.806213185611394|0.0|  0.0|                0.0|               2.0| 38.2|\n",
      "+-------+--------+---------+-----+------------------+------------------+---+-----+-------------------+------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT station,\\\n",
    "              year(min(date)) min_year, \\\n",
    "              year(max(date)) - year(min(date)) num_years, \\\n",
    "              count(precipitation) count,\\\n",
    "              mean(precipitation) mean, \\\n",
    "              stddev(precipitation) stddev, \\\n",
    "              min(precipitation) min, \\\n",
    "              percentile(precipitation,0.25) 25pct, \\\n",
    "              percentile(precipitation,0.50) 50pct, \\\n",
    "              percentile(precipitation,0.75) 75pct, \\\n",
    "              max(precipitation) max \\\n",
    "            FROM precipitations GROUP BY station ORDER BY station\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52111369-e620-4ae8-9614-380c1ac21c9f",
   "metadata": {},
   "source": [
    "## Reliabality\n",
    "\n",
    "To create a relevant and reliable dataset for average precipitation the following will be considered:\n",
    "\n",
    "**Data selection**: Focus on the period with the most comprehensive and consistent data choosing a time frame when a higher number of weather stations are available.\n",
    "\n",
    "**Handling missing data**: For stations with missing data or long gaps consider remove or imputate missing values.\n",
    "\n",
    "**Temporal trends**: Analyze the dataset for any systematic temporal trends (e.g., increasing or decreasing precipitation over the years). \n",
    "\n",
    "**Weighting**: Contribution of each station based on factors like the length of the available data, the quality of the measurements, or the spatial coverage. Spatial coverage per station is 10Km\n",
    "\n",
    "**Spatial coverage**: Stations spread homogenusly on the Netherland area. Some of stations do not include spatial information. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "31047580-4c33-4fed-b34d-bd5f79e950e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import reduce\n",
    "from operator import add\n",
    "\n",
    "def find_desired_year_stations(minimum_year = 1978, min_desired_data_points_per_year = 360):    \n",
    "    # Get stations grouped by year and calculate desired number of records per year\n",
    "    stations_years_complete  = spark.sql(f\"SELECT station, year(date) year, count(precipitation) pre_year FROM precipitations where year(date) >= {minimum_year} GROUP BY station, year(date)\")\n",
    "    stations_years_complete = stations_years_complete.filter(col(\"pre_year\") > min_desired_data_points_per_year)\n",
    "    stations_years_complete = stations_years_complete.select(\"station\",\"year\").orderBy(\"station\",\"year\")\n",
    "\n",
    "    # Group by 'station' and pivot on 'year'\n",
    "    df_transposed = stations_years_complete.groupBy(\"station\").pivot(\"year\").avg(\"year\")\n",
    "\n",
    "    # Count the number of non null years per station\n",
    "    year_columns = df_transposed.columns[1:]\n",
    "    \n",
    "    # expresion to filter year column not null\n",
    "    count_years_expr = reduce(add, [when(col(year_col).isNotNull(), 1).otherwise(0) for year_col in year_columns])\n",
    "    df_transposed = df_transposed.withColumn(\"total_years\", count_years_expr)\n",
    "\n",
    "    # print(f\"Looking for stations with years {len(year_columns)}\")\n",
    "    stations_for_analysis = df_transposed.filter(col(\"total_years\") == len(year_columns)).select(\"station\",\"total_years\")\n",
    "    stations_filter = [item.station for item in stations_for_analysis.collect()]\n",
    "    # print(f\"A total of {len(stations_filter)} stations to be included\")\n",
    "    \n",
    "    return stations_filter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8e43e849-7a73-4078-bce3-54f3661afdff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"@version\":1,\"source_host\":\"rmsryu-vm\",\"message\":\"Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\",\"thread_name\":\"Thread-4\",\"@timestamp\":\"2023-04-06T18:12:23.602+0000\",\"level\":\"WARN\",\"logger_name\":\"org.apache.spark.sql.catalyst.util.package\"}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "starting_years = np.arange(1950, 1960)\n",
    "# Iterate to find best year\n",
    "year_list = []\n",
    "result = []\n",
    "best_num_of_stations = 0\n",
    "for year in starting_years:\n",
    "    temp = len(find_desired_year_stations(year, 360))\n",
    "    result.append((year,temp))\n",
    "    best_initial_year =  year if (temp > best_num_of_stations) else best_initial_year\n",
    "    best_num_of_stations =  temp if (temp > best_num_of_stations) else best_num_of_stations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ca0cf2ec-39e6-41c8-8b3a-79882d404d7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1950, 132),\n",
       " (1951, 144),\n",
       " (1952, 150),\n",
       " (1953, 156),\n",
       " (1954, 174),\n",
       " (1955, 179),\n",
       " (1956, 188),\n",
       " (1957, 204),\n",
       " (1958, 212),\n",
       " (1959, 218)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ee367b45-9af3-448b-a56d-591dc0d81061",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "candiate_min_year = 1955\n",
    "# Selecting year 1955 as baseline with 179 station complete stations datasets and minimum 360 observations\n",
    "stations_filter = find_desired_year_stations(candiate_min_year, 360)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "adc61588-8854-4462-ad87-66052d2bd343",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "179"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(stations_filter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "eb05d180-f40a-45f2-b3cd-e513cbcf67d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 201:=====================>                                  (8 + 4) / 21]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------------------+-------------------+\n",
      "|summary|      precipitation|                  w|\n",
      "+-------+-------------------+-------------------+\n",
      "|  count|              24541|              24541|\n",
      "|   mean| 2.2576964836099185| 178.99690314168126|\n",
      "| stddev|  3.513736968249654|0.07864081706020871|\n",
      "|    min|                0.0|                177|\n",
      "|    25%|0.03240223528619585|                179|\n",
      "|    50%| 0.6435754158476877|                179|\n",
      "|    75%|  3.143575413183793|                179|\n",
      "|    max|  45.87486042257128|                179|\n",
      "+-------+-------------------+-------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "data = data.filter(data.station.isin(stations_filter))\n",
    "data.createOrReplaceTempView(\"final_ds\")\n",
    "df_final = spark.sql(f\"SELECT date, avg(precipitation) precipitation, count(precipitation) w from final_ds where year(date) > {candiate_min_year} group by date\")\n",
    "df_final.summary().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "50f7be58-7605-43b2-b912-075d44046ff6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Save to hadoop\n",
    "df_final.write.mode(\"overwrite\").parquet(f\"{hadoopUrl}/precipitation/data/agg/from/{candiate_min_year}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9e534788-1dfe-4d03-9f40-51cfb5c009e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['829',\n",
       " '467',\n",
       " '666',\n",
       " '447',\n",
       " '740',\n",
       " '747',\n",
       " '442',\n",
       " '743',\n",
       " '462',\n",
       " '234',\n",
       " '672',\n",
       " '543',\n",
       " '073',\n",
       " '434',\n",
       " '974',\n",
       " '356',\n",
       " '087',\n",
       " '348',\n",
       " '541',\n",
       " '970',\n",
       " '584',\n",
       " '443',\n",
       " '910',\n",
       " '737',\n",
       " '670',\n",
       " '139',\n",
       " '559',\n",
       " '352',\n",
       " '160',\n",
       " '012',\n",
       " '570',\n",
       " '539',\n",
       " '843',\n",
       " '742',\n",
       " '973',\n",
       " '964',\n",
       " '749',\n",
       " '458',\n",
       " '565',\n",
       " '067',\n",
       " '573',\n",
       " '075',\n",
       " '327',\n",
       " '221',\n",
       " '081',\n",
       " '897',\n",
       " '163',\n",
       " '912',\n",
       " '453',\n",
       " '224',\n",
       " '019',\n",
       " '667',\n",
       " '449',\n",
       " '046',\n",
       " '140',\n",
       " '549',\n",
       " '905',\n",
       " '736',\n",
       " '835',\n",
       " '558',\n",
       " '147',\n",
       " '839',\n",
       " '455',\n",
       " '328',\n",
       " '228',\n",
       " '669',\n",
       " '011',\n",
       " '756',\n",
       " '341',\n",
       " '329',\n",
       " '967',\n",
       " '678',\n",
       " '229',\n",
       " '066',\n",
       " '076',\n",
       " '354',\n",
       " '578',\n",
       " '464',\n",
       " '439',\n",
       " '837',\n",
       " '840',\n",
       " '345',\n",
       " '238',\n",
       " '456',\n",
       " '901',\n",
       " '913',\n",
       " '914',\n",
       " '827',\n",
       " '156',\n",
       " '338',\n",
       " '830',\n",
       " '963',\n",
       " '754',\n",
       " '755',\n",
       " '965',\n",
       " '834',\n",
       " '450',\n",
       " '471',\n",
       " '968',\n",
       " '461',\n",
       " '741',\n",
       " '437',\n",
       " '751',\n",
       " '665',\n",
       " '673',\n",
       " '896',\n",
       " '832',\n",
       " '090',\n",
       " '016',\n",
       " '833',\n",
       " '148',\n",
       " '240',\n",
       " '239',\n",
       " '158',\n",
       " '838',\n",
       " '236',\n",
       " '564',\n",
       " '567',\n",
       " '444',\n",
       " '562',\n",
       " '336',\n",
       " '068',\n",
       " '907',\n",
       " '358',\n",
       " '899',\n",
       " '550',\n",
       " '680',\n",
       " '561',\n",
       " '681',\n",
       " '342',\n",
       " '022',\n",
       " '454',\n",
       " '064',\n",
       " '668',\n",
       " '588',\n",
       " '750',\n",
       " '463',\n",
       " '077',\n",
       " '763',\n",
       " '010',\n",
       " '546',\n",
       " '563',\n",
       " '222',\n",
       " '911',\n",
       " '225',\n",
       " '235',\n",
       " '752',\n",
       " '746',\n",
       " '252',\n",
       " '056',\n",
       " '339',\n",
       " '844',\n",
       " '333',\n",
       " '915',\n",
       " '764',\n",
       " '831',\n",
       " '080',\n",
       " '760',\n",
       " '017',\n",
       " '583',\n",
       " '161',\n",
       " '758',\n",
       " '151',\n",
       " '082',\n",
       " '353',\n",
       " '579',\n",
       " '674',\n",
       " '828',\n",
       " '085',\n",
       " '664',\n",
       " '226',\n",
       " '340',\n",
       " '145',\n",
       " '330',\n",
       " '542',\n",
       " '332',\n",
       " '572',\n",
       " '084',\n",
       " '438']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stations_filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b3a0c3b-aa7a-4a5f-99c2-693c170a795d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8 - Spark (local)",
   "language": "python",
   "name": "spark-3-python"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
